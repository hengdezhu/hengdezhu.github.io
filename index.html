<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
    <title>Hengde Zhu</title>
  
    <meta name="author" content="Hengde Zhu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px"><td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center"><name>Hengde Zhu</name></p>
                <p>I am a Ph.D. Student at School of Computing and Mathematical Sciences, University of Leicester (UoL), United Kingdom, under the supervision of <a href="https://www.cst.cam.ac.uk/people/ss2796">Dr. Siyang Song</a> and Prof. Rajeev Raman. My research interests center on affective computing and medical image analysis. I earned my Master's degree in Human Technology Interaction from UoL in 2020 and completed Bachelor's degree from South China Normal University (SCNU) in 2017. </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
                <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.png" class="hoverZoomLink">
            </td>
        </tr>
        </tbody></table>
    </td></tr>
    </tbody></table>

    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr>
                <td style="padding:20px 5px;width:100%;vertical-align:middle;">
                    <h2 style="margin: 0; text-align: left;">Selected Publications</h2>
                </td>
            </tr>
        </tbody>
    </table>
    
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;">
                    <div style="display:table;height:100%;width:100%;">
                        <div style="display:table-cell;vertical-align:middle;">
                            <img src='PerFRDiff/pipeline.png' style="max-width: 100%; height: auto; display: block;">
                        </div>
                    </div>
                </td>
    
                <td style="padding:10px;width:70%;vertical-align:middle;">
                    <div style="display:table;height:100%;">
                        <div style="display:table-cell;vertical-align:middle;">
                            <strong>PerFRDiff: Personalised Weight Editing for Multiple Appropriate Facial Reaction Generation</strong>
                            <br>
                            <strong>Hengde Zhu*</strong>, Xiangyu Kong*, Weicheng Xie, Xin Huang, Linlin Shen, Lu Liu, Hatice Gunes, Siyang Song
                            <br>
                            <em>ACM Multimedia</em>, 2024
                            <br>
                            <a href="https://openreview.net/pdf?id=KQVjmulG2I">[PDF]</a>
                            |
                            <a href="https://github.com/xk0720/PerFRDiff">[Code]</a>
                        </div>
                    </div>
                </td>
            </tr>
        </tbody>
    </table>

</body>
  
</html>
